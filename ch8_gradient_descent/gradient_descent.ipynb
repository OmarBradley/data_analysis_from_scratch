{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "# 실수 벡터를 입력하면 실수 하나를 출력해 주는 함수 \n",
    "# v에 속해 있는 항목들의 제곱합을 계산한다.\n",
    "def sum_of_squares(v):\n",
    "    return sum(v_i ** 2 for v_i in v)\n",
    "\n",
    "print sum_of_squares([1,2,5,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4.00001000003\n"
     ]
    }
   ],
   "source": [
    "# Gradient\n",
    "# f 가 단변수 함수인 경우, 점 x에서의 미분값은 x가 아주 조금 변했을 때 f(x)의 변화량을 의미한다. x의 변화량을 다음 식에서는 h로 표기.\n",
    "# 아주 조금 변한다는 것을 반영하기 위해 h를 0에 점근하게 했다.\n",
    "# 이때 미분값은 함수 변화율(difference quotient)의 극한값이다.\n",
    "def difference_quotient(f, x, h):\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "# square 함수의 도함수(derivative)를 구하자.\n",
    "def square(x):\n",
    "    return x * x\n",
    "\n",
    "def derivative_of_square(x):\n",
    "    return 2 * x\n",
    "\n",
    "derivative_estimate = lambda x: difference_quotient(square, x, h=0.00001)\n",
    "\n",
    "print derivative_of_square(2)\n",
    "print derivative_estimate(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 두 계산식에 따른 결과값이 거의 비슷함을 보여 주기 위한 그래프\n",
    "x = range(-10, 10)\n",
    "\n",
    "plt.title(\"Actual Derivatives vs. Estimate\")\n",
    "plt.plot(x, map(derivative_of_square, x), 'rx', label='Actual')\n",
    "plt.plot(x, map(derivative_estimate, x), 'b+', label='Estimate')\n",
    "plt.legend(loc=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 편도함수 변화량 계산\n",
    "# 함수 f의 i번째 편도함수가 v에서 가지는 값\n",
    "def partial_difference_quotient(f, v, i, h):\n",
    "    w = [v_j + (h if j == i else 0)\n",
    "         for j, v_j in enumerate(v)]\n",
    "    \n",
    "    return (f(w) - f(v)) / h\n",
    "\n",
    "def estimate_gradient(f, v, h=0.00001):\n",
    "    return [partial_difference_quotient(f, v, i, h)\n",
    "            for i, _ in enumerate(v)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0442487262054e-06, 0.0, -2.8887490901467167e-06]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# 벡터 뺄셈\n",
    "def vector_subtract(v, w):\n",
    "    return [v_i - w_i\n",
    "            for v_i, w_i in zip(v,w)]\n",
    "\n",
    "def magnitude(v):\n",
    "    return math.sqrt(sum_of_squares(v))\n",
    "\n",
    "def distance(v, w):\n",
    "    return magnitude(vector_subtract(v, w))\n",
    "\n",
    "def step(v, direction, step_size):\n",
    "    return [v_i + step_size * direction_i\n",
    "            for v_i, direction_i in zip(v, direction)]\n",
    "\n",
    "def sum_of_squares_gradient(v):\n",
    "    return [2 * v_i for v_i in v]\n",
    "\n",
    "v = [random.randint(-10, 10) for i in range(3)]\n",
    "\n",
    "tolerance = 0.0000001\n",
    "\n",
    "while True:\n",
    "    gradient = sum_of_squares_gradient(v)\n",
    "    next_v = step(v, gradient, -0.01)\n",
    "    if distance(next_v, v) < tolerance:\n",
    "        break\n",
    "    v = next_v\n",
    "    \n",
    "print v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 적절한 이동 거리 정하기\n",
    "step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "\n",
    "def safe(f):\n",
    "    def safe_f(*args, **kwargs):\n",
    "        try:\n",
    "            return f(*args, **kwargs)\n",
    "        except:\n",
    "            return float('inf')\n",
    "    return safe_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 목적 함수를 최소화시키는 theta를 경사 하강법을 사용해서 찾아준다.\n",
    "def minimize_batch(target_fn, gradient_fn, theta_0, tolerance=0.000001):\n",
    "    step_sizes = [100, 10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001]\n",
    "    \n",
    "    theta = theta_0\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
