## 경사하강법 (gradient descent) ##

- '가장 적합한(best)'이라 함은 '모델의 오류(error)를 최소화하는' 또는 'likelihood(우도)를 최대화하는' 것
- y = f(v) 일때 함수 f를 최대화시키는 입력값 v를 찾아야 한다.

### Gradient ###

> gradient(경사,기울기)는 함수가 가장 빠르게 증가할 수 있는 방향 (편미분 벡터)



> 임의의 시작점을 잡은 후, gradient를 계산하고, gradient의 방향으로 조금 이동하는 과정을 여러 번 반복하는 것

- f(x) 에서 점 x 에서의 미분값은 x가 아주 조금 변했을 때 f(x)의 변화량
- x의 변화량을 다음 식에서는 h로 표기했으며, 아주 조금 변한다는 것을 반영하기 위해 h를 0으로 점근
- 이때 미분값은 함수 변화율(difference quotient)의 극한값

#### 키워드 정리 ####
- 도함수
- 편미분
- 편도함수(partial derivative): 함수 f가 다변수 함수라면 여러 개의 입력 변수 중 하나에 작은 변화가 있을 때 f(x)의 변화량을 알려주는 함수
